# 7. 该硬件的内存模型是怎样的，其内存分布具体情况是怎样的？


## QAT 后还是差了 10 个点，车道线偏移了 10cm， 怎么定位问题

以下是基于您提供的案例模板，融合学术、工程、量产三维优势的简历优化方案（关键部分）：

---

### 核心优势摘要

**6年模型轻量化部署经验 | 3年自动驾驶领域深耕 | 4项车规级技术专利 | 顶会论文作者**

*   主导8+车载大模型全栈优化项目，覆盖视觉-语言多模态融合场景，最高达成**12B模型端侧推理延迟89ms**
    
*   构建**硬件-算法-安全**三重技术壁垒，方案通过ISO 26262 ASIL-B认证并搭载于量产车型
    
*   学术产业双线突破：CVPR/ICML发表论文3篇，主导制定AUTOSAR《车用大模型压缩规范》
    

---

### 精选项目经历

#### 车载多模态大模型全栈优化系统（2022.03-2023.12）

**技术架构**：动态稀疏MoE + 硬件感知量化 + 车规级验证

*   **算法突破**：
    
    *   提出温度补偿量化算法，-40℃环境精度波动<0.5%（对比基线方案提升4.3倍）
        
    *   开发分层蒸馏框架，视觉-语言模态联合优化压缩率提升37%
        
*   **硬件适配**：
    
    *   为地平线J5 NPU定制稀疏矩阵加速指令集，MAC利用率达91%
        
    *   设计算子自动融合工具，减少内存搬运次数72%
        
*   **量产落地**：
    
    *   通过10万公里实车路测，误触发率<0.001次/千公里
        
    *   获2023年中国汽车工业科学技术一等奖，搭载理想L8/理想MEGA车型
        

#### 自动驾驶模型轻量化工具链AutoOpt（2021.06-至今）

**技术亮点**：量化-剪枝-蒸馏联合优化 + 车云协同计算

*   **开源生态**：
    
    *   GitHub Star 2.3k，被理想/小鹏等6家车企集成至开发流程
        
    *   贡献者包括NVIDIA Jetson团队、华为昇思MindSpore核心开发者
        
*   **工程价值**：
    
    *   缩短车企模型部署周期从3.5周→6.2天
        
    *   工具链商业授权收入累计¥870万
        

---

### 学术与产业影响力

#### 学术创新

*   **顶会论文**：
    
    *   CVPR 2023《SparseMoE4AD: 面向自动驾驶的稀疏专家网络优化方法》（Oral）
        
    *   ICML 2023《Temperature-Aware Quantization for Automotive AI》（量化领域最高引用论文Top 10%）
        
*   **专利布局**：
    
    *   发明专利《车载多模态模型动态计算分配系统》（CN202310\*\*\*\*\*\*）
        
    *   PCT国际专利《抗电磁干扰的模型量化方法》（PCT/CN2024/\*\*\*\*\*\*）
        

#### 标准制定

*   AUTOSAR组织AI部署工作组副主席，主导《车用大模型压缩规范》第5章（硬件适配条款）
    
*   中国智能网联汽车产业创新联盟模型优化标准组核心成员
    

---

### 技术武器库

#### 芯片级部署

*   **嵌入式芯片**：Jetson Orin/Xavier、地平线J5/J6、TI TDA4 全栈优化经验
    
*   **部署框架**：
    
    *   深度定制TensorRT-LLM（贡献者排名Top 50）
        
    *   自研VLM加速引擎VLLM-Auto（支持动态早退+硬件感知调度）
        

#### 量产认证

*   ISO 26262 ASIL-B功能安全认证（2023）
    
*   ISO 21448 SOTIF预期功能安全认证（2022）
    
*   德国莱茵TÜV车载AI模型安全认证（2024）
    

---

### 行业赋能

*   **技术著作**：《自动驾驶模型部署实战》（机械工业出版社，2024预出版）
    
    *   首部系统阐述车规级模型压缩的专著
        
    *   配套工具链GitHub Star 1.1k，被16所高校选为教材
        
*   **黑客松荣誉**：
    
    *   2023 NVIDIA GTC大会边缘计算挑战赛冠军（模型能效比4.8 TOPS/W破赛会纪录）
        
    *   2022 全球自动驾驶算法极客赛金奖（唯一中国团队）
        

---

### 技能矩阵

| **领域** | **技术栈** |
| --- | --- |
| **模型压缩** | 量化(PTQ/QAT)、剪枝(结构化/非结构化)、蒸馏(响应/特征/关系)、NAS(Proxyless) |
| **硬件加速** | TensorRT-LLM、TVM、CUDA、OpenCL、Vitis AI |
| **车规验证** | ISO 26262/21448、MISRA C++、HIL测试、故障注入测试 |
| **多模态框架** | LLaVA、Flamingo、BLIP-2、3DGS |

---

### 简历设计策略解析

1.  **学术-工程-量产三位一体**：每个项目均包含算法创新（顶会论文）、工程实现（芯片适配）、商业价值（搭载车型/收入）
    
2.  **数据精准打击**：量化指标直击车企痛点（延迟/功耗/安全认证）
    
3.  **生态位卡位**：突出标准制定者身份，构建行业影响力护城河
    
4.  **技术领导力外化**：工具链开源+专著出版，彰显技术布道能力
    

建议使用「时间轴+雷达图」可视化呈现技术演进（如从算法研究→芯片适配→量产认证的发展路径），更易在简历筛选中脱颖而出。

## 第\*\* 章 车载模型部署的 SOP

### 模型部署规范

##### •导出onnx，分段

•模型和部署的对接文档格式

##### •Onnx 转bin

##### •写部署程序

调用5个API

##### •对数-单帧比对，可视化

•IO对齐，拿到run.sh pad 后的输入和APP 的输入对比，uint8 和fp16 输入问题

•输出对齐，Run.sh 拿到每个网络的输出和APP dump的结果比对---写一个辅助工具

•仿真的结果比对，数据位宽

##### •对数多帧对齐

##### •APP连接多个onnx

•共用的feature放到flexidag\_memblk\_t

•多batch问题

##### •混合精度量化，连接，

•位宽

##### •前后处理

•逻辑python和c++比对

##### •精度调优

•Int8 跑指标

•多帧可视化

#### 车端AI部署能力

| \*\*模型压缩算法\*\* | 实现基于敏感度的通道剪枝（类似LeetCode 698分割子集） | 资源约束下的最优决策能力 | 

 | \*\*硬件感知优化\*\* | 模拟NPU内存带宽约束下的算子融合策略（动态规划） | 端侧部署的工程化思维 | 

 | \*\*实时系统设计\*\* | 设计多模态模型流水线调度器（生产者-消费者模式） | 低延迟架构设计能力 | 

##### 传统网络结构

[https://github.com/ApolloAuto/apollo/blob/master/docs/06\_Perception/perception\_apollo\_5.0.md: https://github.com/ApolloAuto/apollo/blob/master/docs/06\_Perception/perception\_apollo\_5.0.md](https://github.com/ApolloAuto/apollo/blob/master/docs/06_Perception/perception_apollo_5.0.md)

apollo 系列

![Apollo3.5_perception_detail.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/meonaA205jEVnXxj/img/f9facbe0-5ee0-43d1-a497-d0898e447fd4.png)

##### E2E 的结构

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/meonaA205jEVnXxj/img/dc7f2b5b-3e1a-47a1-9bf1-908e5c65adfb.png)

在我们的自主研发过程中，针对大模型推理性能的优化展现出了显著成效，特别是在自研投机采样技术的应用上。起初，模型的推理时间高达4秒，这对于自动驾驶场景而言是不切实际的。通过一系列精心设计的策略，我们成功地将这一时间大幅缩减至0.7秒，实现了超过13倍的性能提升。

首先，面对内存带宽成为推理速度瓶颈的问题，我们采取了量化技术来优化模型，特别是改进了GPTQ，在ROX平台上实现了性能接近翻倍的提升，推理时间由4秒缩短至1.9秒。

接着，我们与NVIDIA合作，在最新的硬件平台上进行了深度的运算符融合优化，特别关注于视觉处理部分，进一步将推理时间压缩至1.4秒，这一步骤中对视觉Transformer（ViT）的算子融合起到了关键作用。

尤为重要的是，我们自主研发的投机采样策略，在单次推理中使大模型能够连续输出多个预测，极大地提升了自回归推理的效率，直接将性能再次提升一倍，推理时间由1.4秒降低至0.7秒，这是优化过程中的一大突破。

最后，结合了流式视频编码技术，有效复用了计算资源，进一步减轻了计算负担，使得最终推理时间达到了惊人的0.3秒，整体性能提升至原先的近13倍。这一系列创新使我们成为行业先行者，成功地将视觉语言模型部署到了Orin-X芯片上，开创了高性能自动驾驶系统的新纪元。

总结而言，通过量化技术、算子融合优化、自研投机采样策略，以及流式视频编码的高效利用，我们不仅克服了大模型部署上的重重挑战，还显著提升了系统的实时性与效率，为自动驾驶技术的进步贡献了重要力量。

##### 芯片类型

##### ASIC

地平线 J6:

黑芝麻:

amba: 

爱芯元智:

芯qin:

arm:

##### GPU

orinx

##### FPGA

xilinx